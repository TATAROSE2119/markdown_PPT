---
marp: true
size: 16:9
paginate: true



style: |
  section {
    font-family: 'Microsoft YaHei', sans-serif;
    font-size: 17px;
    line-height: 1.6;
    
  }

---

# <!--fit--> Double low-rank representation with projection distance penalty for clustering
作者：Zhiqiang Fu
时间：2015
汇报人：潘岩

![bg cover opacity:.1](https://bkimg.cdn.bcebos.com/pic/8326cffc1e178a82f156e505fd03738da977e829)

---
![bg cover opacity:.1](https://bkimg.cdn.bcebos.com/pic/8326cffc1e178a82f156e505fd03738da977e829)


### 1. **公式 1：LRR (Low-Rank Representation) 优化问题**

公式 1 主要用于表示传统的低秩表示方法（LRR），它的目标是最小化重构误差，并通过低秩约束来学习数据的结构。

$$
\min_{Z,E} \|Z\|_* + \lambda \|E\|_{2,1}, \quad \text{s.t.} \quad X = XZ + E
$$


- $X$  是原始数据矩阵，包含了所有样本。
- $Z$ 是表示矩阵，用于构建样本之间的相似度图。通过低秩约束，$Z$  将被学得是低秩的，这意味着它能捕捉数据的全局结构。
- $Z$ 是重构误差矩阵，表示从原始数据矩阵 $X$ 到低秩表示 $XZ$ 的差异。该误差矩阵需要最小化。
- $\|Z\|_*$ 是核范数（Nuclear Norm），用于表示 $Z$ 的低秩性质。核范数是矩阵的奇异值之和，这个范数可以帮助控制矩阵的秩，迫使 $Z$ 是低秩的。
- \( \|E\|_{2,1} \) 是矩阵的 L2,1 范数，用于对误差矩阵 \( E \) 进行惩罚。L2,1 范数是每一行的L2范数之和，旨在使得一些数据点的误差较小，从而减少噪声影响。
- 约束条件 \( X = XZ + E \) 表示数据矩阵 \( X \) 可以通过一个低秩表示矩阵 \( Z \) 和误差矩阵 \( E \) 来重构，学习出的 \( Z \) 应该尽可能精确地重构数据。
---

![bg cover opacity:.1](https://bkimg.cdn.bcebos.com/pic/8326cffc1e178a82f156e505fd03738da977e829)

### 2. **公式 2：LatLRR（Latent Low-Rank Representation）优化问题**

公式 2 代表了LatLRR方法，进一步改进了LRR方法，引入了潜在数据（Latent Data）来增强数据表示。

$$
\min_{Z,P,E} \|Z\|_* + \|P\|_* + \lambda \|E\|_1, \quad s.t X = XZ + PX + E
$$

**解释**：
- \( Z \) 是表示矩阵（与公式 1 相同）。
- \( P \) 是一个投影矩阵，能够帮助捕捉数据的潜在结构。通过引入 \( P \)，LatLRR不仅依赖于观测数据，还可以利用潜在的未观测数据进行学习，弥补了原始数据中可能存在的不足。
- \( E \) 是重构误差矩阵（与公式 1 相同）。
- \( \|P\|_* \) 是 \( P \) 的核范数，旨在通过约束 \( P \) 来引导模型学习到更有意义的潜在结构。
- \( \|E\|_1 \) 是 \( E \) 的 L1 范数，用来对重构误差进行惩罚，减少噪声的影响。
- 约束条件 \( X = XZ + PX + E \) 表示，除了通过 \( Z \) 来表示样本外，潜在数据 \( PX \) 也能参与到数据重构中，帮助提升模型的表示能力。
---

![bg cover opacity:.1](https://bkimg.cdn.bcebos.com/pic/8326cffc1e178a82f156e505fd03738da977e829)

### 3. **公式 3：DLRR（Double Low-Rank Representation）优化问题**

公式 3 代表了双低秩表示（DLRR）方法，它结合了低秩约束来同时学习数据的样本结构和特征结构。

\[
\min_{Z,P,E} \|Z\|_* + \|P\|_* + \lambda \|E\|_1, \quad \text{s.t.} \quad X = PXZ + E
\]

**解释**：
- \( Z \) 和 \( P \) 的含义与公式 2 中相同：\( Z \) 用于捕捉样本之间的相似性，\( P \) 用于学习特征空间中的结构。
- \( E \) 是重构误差矩阵，和前两个公式一致。
- 约束条件 \( X = PXZ + E \) 表示，原始数据 \( X \) 可以通过投影矩阵 \( P \) 和表示矩阵 \( Z \) 的组合来表示，同时允许一定的误差 \( E \)。
- 该公式的核心思想是通过将数据同时在样本空间和特征空间上进行低秩表示，来捕捉数据的双重结构。相比传统的LRR方法，DLRR能够同时考虑样本和特征的结构，提升模型的表示能力。

### 总结：

- **公式 1**：低秩表示（LRR）方法，侧重于从原始数据中提取出一个低秩表示，构建样本之间的相似度图。
- **公式 2**：潜在低秩表示（LatLRR）方法，结合了潜在数据来进一步增强数据表示的能力，改进了LRR。
- **公式 3**：双低秩表示（DLRR）方法，通过在样本和特征空间同时施加低秩约束，进一步提升了数据表示的效果。

这些公式的核心思想是通过低秩表示来学习数据的潜在结构，使得模型能够在聚类等任务中更好地捕捉数据的内在规律。
